---
title: Project Overview
tags: [machine_learning, object_detection, ios, swift]
keywords:
summary: 
sidebar: mydoc_sidebar
permalink: doc202301_01.html
folder: doc202301
---

## Overview

Taking image input from the iPhone/Android Camera, then process the images with GPUImage/OpenCV libraries to visualize the images. To detect the shapes, train the visualized images with yolov8 ML model and converted it into a CoreML model to display recognition results on the iPhone, and train with Tensorflow Lite library(MobileNet V2 model) for the Android devices.

## Languages and Libraries

- iOS App: Swift + Storyboard
- Android App: Kotlin
- Windows Desktop App: .NET 8 + WPF
- Machine Learning Model
    - iOS: yolov8 model -> CoreML conversion
    - Android: Tensorflow Lite -> Float16 Quantization
- [GPUImage2](https://github.com/BradLarson/GPUImage2) - iOS
    - I tried GPUImage3(the latest version), but the library has changed its structure and some filters are not implemented(yet?). So, I had to GPUImage2 and added custom filter for barcode detector.
- [Android-GPUImage](https://github.com/cats-oss/android-gpuimage) - Android
    - OpenGL ES 2.0 Based Filters
- [OpenCV 3.4.x](https://github.com/opencv/opencv/tree/3.4.16) - iOS/Android
    - I also tried OpenCV 4.x, but I couldn't get OpenCV 4.x Camera input on Android Devices correctly(not sure what caused it), so I tested V3.4.16 and chose it. 



{% include links.html %}
