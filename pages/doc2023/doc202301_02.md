---
title: Machine Learning - Shape Detection Android
tags: [machine_learning object_detection android kotlin gpuimage]
keywords:
summary: "This project aimed at recognizing hidden shapes and arrangements, and authenticating genuine products with encrypted codes. It was conducted from June to December 2023."
sidebar: mydoc_sidebar
permalink: doc202301_02.html
folder: doc2023
---

## Shape Detection - Android

Taking images from the Android Device Camera, processed the images using the GPUImage library, and visualized them. We conducted Machine Learning Training using the TensorFlow Lite Library and the MobileNetV2 model, then converted it into a Float16-Quantized TFLite model to display recognition results on the Android Device.

## Machine Learning Library and Model - Tensorflow Lite / MobileNetV2_320

For the Object Detection App of Android devices, we utilized the most suitable Tensorflow Lite Library along with the MobileNetV2 Model.



### Traning Model Export To Tensorflow Lite

Traning and model conversion had been done on Google Colab using Colab Notebook below. 

[Colab Notebook - MobileNetV2_TFLite2_ObjectDetection](20230813_MobilenetV2_320_Train_TFLite2_Object_Detction_Model.ipynb)

When exporting the model to a TF Lite file without specifying the maximum number of recognitions, the number of detections is limited to 10. Therefore, it is essential to include the following option: (100 or the desired maximum number of recognitions).
> --max_detections 100

```python

# Make a directory to store the trained TFLite model
#!mkdir /content/drive/MyDrive/mobilenetv2_320/custom_model_lite2
colab_project_folder = '/content/drive/MyDrive/colab03'
output_directory = '/content/drive/MyDrive/mobilenetv2_320/custom_model_lite2'

# Path to training directory (the conversion script automatically chooses the highest checkpoint file)
last_model_path = '/content/drive/MyDrive/mobilenetv2_320/training'

!python {colab_project_folder}/models/research/object_detection/export_tflite_graph_tf2.py \
    --trained_checkpoint_dir {last_model_path} \
    --output_directory {output_directory} \
    --max_detections 100 \
    --pipeline_config_path {pipeline_file}


```

### TF Lite Quantization

Convert the exported TF Lite file to a float16 quantization file.

```python

import tensorflow as tf
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.float16]
conv_result = converter.convert()
with open(tflite_model_dir + '/float16_quant.tflite', 'wb') as f:
  f.write(conv_result)

```


## Android App - Kotlin / GPUImage

The Android App is developed using the Kotlin language. The GPUImage available on Android is implemented based on OpenGL ES 2.0, which differs in implementation from iOS's GPUImage. Consequently, custom filters cannot be used. Instead, the Camera Source was modified to invoke GPUImage Filters upon frame creation, and the resulting output is passed to the ObjectorDetector to perform Shape Detection.

### ObjectorDetector Initialization

Initialize the ObjectorDetector to use the Float16-Quantized TFLite file.

```Java

    if (mlCodeDetector == null) {
        // Step 2: Initialize the detector object
        val options = ObjectDetector.ObjectDetectorOptions.builder()
            .setMaxResults(-1)
            .setScoreThreshold(MLDetectActivity.detectThreshold)
            .build()
        mlCodeDetector = ObjectDetector.createFromFileAndOptions(
            mContext,
            "float16_metadata_maxout_100.tflite",
            options
        )
    }

```

Initialize the GPUImage filter settings, apply the filter to the image, and return the result.

```Java

    private fun GetDCOPBitmap_GPUImg(
        lfrmCamPreview: Frame,
        lbcdCallback: MLDetectTrackerCallback?
    ): Bitmap?  {
        val bmpImageOrg = getBitmapFromRGBFrame(lfrmCamPreview)

        if (_GPUIMG == null) {
            _GPUIMG = GPUImage(mContext)
            var filterGroup = GPUImageFilterGroup()

            var grayscaleFilter = GPUImageGrayscaleFilter()
            filterGroup.addFilter(grayscaleFilter)

            val sharpen = GPUImageSharpenFilter()
            sharpen.setSharpness(1.0f)
            filterGroup.addFilter(sharpen)

            val sobelEdge = GPUImageSobelEdgeDetectionFilter()
            //sobelEdge.setLineSize(1.0f)
            filterGroup.addFilter(sobelEdge)

            var colorInv = GPUImageColorInvertFilter()
            filterGroup.addFilter(colorInv)

            var boxBlur = GPUImageBoxBlurFilter()
            boxBlur.setBlurSize(1.0f)
            //filterGroup.addFilter(boxBlur)

            val gamma = GPUImageGammaFilter()
            gamma.setGamma(0.4f)
            //filterGroup.addFilter(gamma)

            _GPUIMG!!.setFilter(filterGroup)
        }
        _GPUIMG!!.setImage(bmpImageOrg)
        val filteredBitmap = _GPUIMG!!.bitmapWithFilterApplied

        return filteredBitmap
    }


```

Receive the image processed by the GPUImage filter, convert it to a TensorImage, and perform Object Detection.

```Java

    fun DetectCodes(bmpImage: Bitmap, bcdCallback: MLDetectTrackerCallback?): Bitmap? {
        // Step 1: Create TFLite's TensorImage object
        val image = TensorImage.fromBitmap(bmpImage)

        if (mlCodeDetector == null) {
            // Step 2: Initialize the detector object
            val options = ObjectDetector.ObjectDetectorOptions.builder()
                .setMaxResults(-1)
                .setScoreThreshold(MLDetectActivity.detectThreshold)
                .build()
            mlCodeDetector = ObjectDetector.createFromFileAndOptions(
                mContext,
                "float16_metadata_maxout_100.tflite",
                options
            )
        }

        // Step 3: Feed given image to the detector
        val results = mlCodeDetector?.detect(image)

        val shapeProc = ShapeProcessor(results, bmpImage)

        val imgWithResult = shapeProc.imageOut
        if (!shapeProc.resultCode.equals("none", true)) {
            val bcdData = Barcode()
            bcdData.displayValue = shapeProc.resultCode
            bcdCallback?.onDetectedQrCode(bcdData)
        }

        return imgWithResult
    }


```









{% include links.html %}
