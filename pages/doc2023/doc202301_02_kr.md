---
title: Machine Learning - Shape Detection Android
tags: [machine_learning, object_detection, android, kotlin]
keywords:
summary: "이 프로젝트는 숨겨진 도형의 모양과 배열을 인식하고, 암호화된 코드로 정품을 인증하는 소프트웨어 개발 프로젝트이며, 2023년 6월 ~ 12월 진행되었음"
sidebar: mydoc_sidebar
permalink: doc202301_02_kr.html
folder: doc2023
---

## Shape Detection - Android

아이폰 카메라에서 이미지 입력을 받아 GPUImage/OpenCV 라이브러리를 사용하여 이미지 처리를 하고 이미지를 시각화했습니다. yolov8 ML 모델을 사용하여 Machin Learning Traning을 진행하고 이를 CoreML 모델로 변환하여 아이폰에서 인식 결과를 표시함.


## Machine Learning Library and Model - Tensorflow Lite / MobileNetV2_320

Android Devices용 Object Detection App의 경우, 그에 가장 적합한 Tensorflow Lite Library와 MobileNetV2_320 Model을 사용하였다.

[Colab Notebook](20230813_MobilenetV2_320_Train_TFLite2_Object_Detction_Model.ipynb)



### Traning Model Export To Tensorflow Lite

Model을 TF Lite 파일로 Export 할 때 최대 인식 수를 지정하지 않을 경우, Detection의 수가 10개로 제한되므로, 다음 옵션을 반드시 추가해야 한다. (100 또는 원하는 최대 인식 수)
> --max_detections 100

```python

# Make a directory to store the trained TFLite model
#!mkdir /content/drive/MyDrive/mobilenetv2_320/custom_model_lite2
colab_project_folder = '/content/drive/MyDrive/colab03'
output_directory = '/content/drive/MyDrive/mobilenetv2_320/custom_model_lite2'

# Path to training directory (the conversion script automatically chooses the highest checkpoint file)
last_model_path = '/content/drive/MyDrive/mobilenetv2_320/training'

!python {colab_project_folder}/models/research/object_detection/export_tflite_graph_tf2.py \
    --trained_checkpoint_dir {last_model_path} \
    --output_directory {output_directory} \
    --max_detections 100 \
    --pipeline_config_path {pipeline_file}


```

### TF Lite Quantization

Export된 TF Lite 파일을 float16 Quatization 파일로 변환한다. 

```python

import tensorflow as tf
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.float16]
conv_result = converter.convert()
with open(tflite_model_dir + '/float16_quant.tflite', 'wb') as f:
  f.write(conv_result)

```

## Android App - Kotlin / GPUImage

Android App은 Kotlin Language를 사용하였으며, Android에서 사용가능한 GPUImage는 OpenGL ES 2.0 기반으로 구현되어 iOS의 GPUImage와는 구현 방식이 다르다. 때문에, Custom Filter 를 사용할 수 없고, Camera Source를 수정하여 Frame 생성시 GPUImage Filter를 호출하고, 그 결과를 ObjectorDetector에 전달하여 Shape Detection을 수행하도록 하였다.

### ObjectorDetector Initialization

Float16-Quantized TFLite 파일을 이용하도록 ObjectorDetector를 초기화한다.

```Java

    if (mlCodeDetector == null) {
        // Step 2: Initialize the detector object
        val options = ObjectDetector.ObjectDetectorOptions.builder()
            .setMaxResults(-1)
            .setScoreThreshold(MLDetectActivity.detectThreshold)
            .build()
        mlCodeDetector = ObjectDetector.createFromFileAndOptions(
            mContext,
            "float16_metadata_maxout_100.tflite",
            options
        )
    }

```

GPUImage의 필터 설정을 초기화하고, 이미지에 필터를 적용하여 결과를 반환한다.

```Java

    private fun GetDCOPBitmap_GPUImg(
        lfrmCamPreview: Frame,
        lbcdCallback: MLDetectTrackerCallback?
    ): Bitmap?  {
        val bmpImageOrg = getBitmapFromRGBFrame(lfrmCamPreview)

        if (_GPUIMG == null) {
            _GPUIMG = GPUImage(mContext)
            var filterGroup = GPUImageFilterGroup()

            var grayscaleFilter = GPUImageGrayscaleFilter()
            filterGroup.addFilter(grayscaleFilter)

            val sharpen = GPUImageSharpenFilter()
            sharpen.setSharpness(1.0f)
            filterGroup.addFilter(sharpen)

            val sobelEdge = GPUImageSobelEdgeDetectionFilter()
            //sobelEdge.setLineSize(1.0f)
            filterGroup.addFilter(sobelEdge)

            var colorInv = GPUImageColorInvertFilter()
            filterGroup.addFilter(colorInv)

            var boxBlur = GPUImageBoxBlurFilter()
            boxBlur.setBlurSize(1.0f)
            //filterGroup.addFilter(boxBlur)

            val gamma = GPUImageGammaFilter()
            gamma.setGamma(0.4f)
            //filterGroup.addFilter(gamma)

            _GPUIMG!!.setFilter(filterGroup)
        }
        _GPUIMG!!.setImage(bmpImageOrg)
        val filteredBitmap = _GPUIMG!!.bitmapWithFilterApplied

        return filteredBitmap
    }


```

GPUImage 필터에서 처리된 이미지를 전달받아 TensorImage로 변환하고, Objection Detection을 수행한다.

```Java

    fun DetectCodes(bmpImage: Bitmap, bcdCallback: MLDetectTrackerCallback?): Bitmap? {
        // Step 1: Create TFLite's TensorImage object
        val image = TensorImage.fromBitmap(bmpImage)

        if (mlCodeDetector == null) {
            // Step 2: Initialize the detector object
            val options = ObjectDetector.ObjectDetectorOptions.builder()
                .setMaxResults(-1)
                .setScoreThreshold(MLDetectActivity.detectThreshold)
                .build()
            mlCodeDetector = ObjectDetector.createFromFileAndOptions(
                mContext,
                "float16_metadata_maxout_100.tflite",
                options
            )
        }

        // Step 3: Feed given image to the detector
        val results = mlCodeDetector?.detect(image)

        val shapeProc = ShapeProcessor(results, bmpImage)

        val imgWithResult = shapeProc.imageOut
        if (!shapeProc.resultCode.equals("none", true)) {
            val bcdData = Barcode()
            bcdData.displayValue = shapeProc.resultCode
            bcdCallback?.onDetectedQrCode(bcdData)
        }

        return imgWithResult
    }


```









{% include links.html %}
